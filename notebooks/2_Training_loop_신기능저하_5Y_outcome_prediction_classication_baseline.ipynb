{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(f\"현재 사용 가능한 GPU 개수: {torch.cuda.device_count()}\")\n",
    "print(f\"현재 GPU 이름: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_CSV = Path(\"/home/khdp-user/workspace/dataset/CSV/GT_label.csv\")\n",
    "PATCH_ROOT = Path(\"/home/khdp-user/workspace/MIL_patch\")\n",
    "PATCH_SIZE = 256\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "OUT_DIR = Path(\"/home/khdp-user/workspace/MIL_run_cls\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_PATH = os.path.join(OUT_DIR, \"dataset.csv\")\n",
    "BEST_MODEL_PATH = OUT_DIR / \"best_model.pt\"\n",
    "SPLIT_CSV_PATH  = OUT_DIR / \"dataset.csv\"\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resplit_mil_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    train_ratio: float = 0.8,\n",
    "    val_ratio: float = 0.1,\n",
    "    test_ratio: float = 0.1,\n",
    "    random_state: int = 42,\n",
    "    gt_col: str = \"GT\",\n",
    "    split_col: str = \"split\",\n",
    "):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \\\n",
    "        \"Ratios must sum to 1.\"\n",
    "\n",
    "    mil_df = df[\n",
    "        (df[split_col] == \"train\") &\n",
    "        (df[gt_col].notna())\n",
    "    ].copy()\n",
    "\n",
    "    if len(mil_df) == 0:\n",
    "        raise ValueError(\"No samples found with split=='train' and GT not null.\")\n",
    "\n",
    "\n",
    "    train_df, temp_df = train_test_split(\n",
    "        mil_df,\n",
    "        test_size=(1 - train_ratio),\n",
    "        random_state=random_state,\n",
    "        shuffle=True,\n",
    "        stratify=mil_df[gt_col] if mil_df[gt_col].nunique() > 1 else None\n",
    "    )\n",
    "\n",
    "    val_size = val_ratio / (val_ratio + test_ratio)\n",
    "\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=(1 - val_size),\n",
    "        random_state=random_state,\n",
    "        shuffle=True,\n",
    "        stratify=temp_df[gt_col] if temp_df[gt_col].nunique() > 1 else None\n",
    "    )\n",
    "\n",
    "    mil_df.loc[train_df.index, split_col] = \"train\"\n",
    "    mil_df.loc[val_df.index,   split_col] = \"val\"\n",
    "    mil_df.loc[test_df.index,  split_col] = \"test\"\n",
    "\n",
    "    mil_df.to_csv(SPLIT_CSV_PATH, index=False)\n",
    "\n",
    "    print(\"[MIL Resplit Summary]\")\n",
    "    print(\"Total used:\", len(mil_df))\n",
    "    print(\"Train:\", len(train_df))\n",
    "    print(\"Val  :\", len(val_df))\n",
    "    print(\"Test :\", len(test_df))\n",
    "    return mil_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(LABEL_CSV)\n",
    "slide_split = resplit_mil_dataframe(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    train_tf = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Resize(PATCH_SIZE, PATCH_SIZE),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    val_tf = A.Compose([\n",
    "        A.Resize(PATCH_SIZE, PATCH_SIZE),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    return train_tf, val_tf\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0, mode=\"min\"):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return True\n",
    "\n",
    "        improved = (\n",
    "            score < self.best_score - self.min_delta\n",
    "            if self.mode == \"min\"\n",
    "            else score > self.best_score + self.min_delta\n",
    "        )\n",
    "\n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            return False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MIL Dataset: Bag = slide, Instance = patch\n",
    "# Folder: PATCH_ROOT / SlideName / images / *.png\n",
    "# ============================================================\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, df_slide, patch_root: Path, transform=None,\n",
    "                 max_patches=None, sample_mode=\"random\"):\n",
    "        \"\"\"\n",
    "        df_slide: SlideName, GT, split columns\n",
    "        max_patches: 한 slide에서 사용할 patch 최대 수 (None=전부)\n",
    "        sample_mode: \"random\" | \"first\"\n",
    "        \"\"\"\n",
    "        self.df = df_slide.reset_index(drop=True)\n",
    "        self.patch_root = Path(patch_root)\n",
    "        self.transform = transform\n",
    "        self.max_patches = max_patches\n",
    "        self.sample_mode = sample_mode\n",
    "\n",
    "        # sanity check columns\n",
    "        for c in [\"SlideName\", \"GT\", \"split\"]:\n",
    "            if c not in self.df.columns:\n",
    "                raise ValueError(f\"Missing required column: {c}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _collect_patch_paths(self, slide_name: str):\n",
    "        img_dir = self.patch_root / slide_name / \"images\"\n",
    "        if not img_dir.exists():\n",
    "            return []\n",
    "        return sorted(img_dir.glob(\"*.png\"))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        slide_name = str(row[\"SlideName\"])\n",
    "        gt_val = row[\"GT\"]\n",
    "\n",
    "        # GT 예외 처리: NaN이면 사용 불가\n",
    "        if pd.isna(gt_val):\n",
    "            raise RuntimeError(f\"GT is NaN for slide {slide_name}. This should not be in MIL split set.\")\n",
    "\n",
    "        y = torch.tensor(int(gt_val)).long()\n",
    "\n",
    "        patch_paths = self._collect_patch_paths(slide_name)\n",
    "        if len(patch_paths) == 0:\n",
    "            # MIL에서 patch 없는 slide는 학습 불가 -> 명확히 터뜨림\n",
    "            raise RuntimeError(f\"No patches found for slide: {slide_name} at {self.patch_root/slide_name/'images'}\")\n",
    "\n",
    "        # sampling\n",
    "        if self.max_patches is not None and len(patch_paths) > self.max_patches:\n",
    "            if self.sample_mode == \"first\":\n",
    "                patch_paths = patch_paths[:self.max_patches]\n",
    "            else:\n",
    "                patch_paths = list(np.random.choice(patch_paths, self.max_patches, replace=False))\n",
    "\n",
    "        imgs = []\n",
    "        for p in patch_paths:\n",
    "            img = cv2.imread(str(p))\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(image=img)[\"image\"]\n",
    "            else:\n",
    "                # fallback\n",
    "                img = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "\n",
    "            imgs.append(img)\n",
    "\n",
    "        if len(imgs) == 0:\n",
    "            raise RuntimeError(f\"All patches failed to load for slide: {slide_name}\")\n",
    "\n",
    "        x = torch.stack(imgs, dim=0)  # (N,3,H,W)\n",
    "        return x, y, slide_name\n",
    "\n",
    "\n",
    "class MILTopKMean(nn.Module):\n",
    "    def __init__(self, backbone=\"resnet50\", num_classes=2, top_k=10):\n",
    "        super().__init__()\n",
    "        self.top_k = int(top_k)\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone,\n",
    "            pretrained=True,\n",
    "            num_classes=0,\n",
    "            global_pool=\"avg\",\n",
    "        )\n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.classifier = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)         # (N,D)\n",
    "        inst_logits = self.classifier(feats)  # (N,2)\n",
    "        pos = inst_logits[:, 1]  # (N,)\n",
    "\n",
    "        k = min(self.top_k, pos.size(0))\n",
    "        topk_pos, _ = torch.topk(pos, k=k)\n",
    "        slide_pos = topk_pos.mean()  # scalar\n",
    "\n",
    "        slide_logits = torch.stack(\n",
    "            [torch.tensor(0.0, device=x.device), slide_pos]\n",
    "        ).unsqueeze(0)  # (1,2)\n",
    "\n",
    "        return slide_logits\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mil(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_prob = []\n",
    "    y_pred = []\n",
    "\n",
    "    for x, y, _slide in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        # loader batch_size=1 => x: (1,N,3,H,W)\n",
    "        x = x.squeeze(0).to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        logits = model(x)  # (1,2)\n",
    "        prob = torch.softmax(logits, dim=1)[:, 1]  # (1,)\n",
    "        pred = torch.argmax(logits, dim=1)        # (1,)\n",
    "\n",
    "        y_true.append(int(y.item()))\n",
    "        y_prob.append(float(prob.item()))\n",
    "        y_pred.append(int(pred.item()))\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    # AUC는 단일 클래스만 있으면 계산 불가\n",
    "    auc = None\n",
    "    if len(set(y_true)) > 1:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"auc\": auc,\n",
    "        \"cm\": confusion_matrix(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# Train\n",
    "# ============================================================\n",
    "def train_mil(slide_split_df, top_k=10, max_patches=300, sample_mode=\"random\"):\n",
    "    train_tf, val_tf = get_transforms()\n",
    "\n",
    "    df_tr = slide_split_df[slide_split_df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "    df_va = slide_split_df[slide_split_df[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "\n",
    "    # DataLoader: slide 단위로 배치 처리 => batch_size=1\n",
    "    SLIDE_BATCH_SIZE = 1\n",
    "\n",
    "    dl_tr = DataLoader(\n",
    "        MILDataset(df_tr, PATCH_ROOT, transform=train_tf, max_patches=max_patches, sample_mode=sample_mode),\n",
    "        batch_size=SLIDE_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    dl_va = DataLoader(\n",
    "        MILDataset(df_va, PATCH_ROOT, transform=val_tf, max_patches=max_patches, sample_mode=sample_mode),\n",
    "        batch_size=SLIDE_BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model = MILTopKMean(backbone=\"resnet50\", num_classes=2, top_k=top_k).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    early = EarlyStopping(patience=5, min_delta=1e-4, mode=\"min\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        pbar = tqdm(dl_tr, desc=f\"[Train] Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for x, y, _slide in pbar:\n",
    "            # x: (1,N,3,H,W) -> (N,3,H,W)\n",
    "            x = x.squeeze(0).to(DEVICE)\n",
    "            y = y.to(DEVICE)  # (1,)\n",
    "\n",
    "            logits = model(x)               # (1,2)\n",
    "            loss = criterion(logits, y)     # y shape ok (1,)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\", n_patches=x.size(0))\n",
    "\n",
    "        train_loss = float(np.mean(train_losses))\n",
    "\n",
    "        # Validation loss/metrics\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        for x, y, _slide in dl_va:\n",
    "            x = x.squeeze(0).to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            val_losses.append(loss.item())\n",
    "        val_loss = float(np.mean(val_losses)) if val_losses else 0.0\n",
    "\n",
    "        is_best = early.step(val_loss)\n",
    "        if is_best:\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "\n",
    "        val_metrics = evaluate_mil(model, dl_va)\n",
    "        auc_str = \"None\" if val_metrics[\"auc\"] is None else f\"{val_metrics['auc']:.4f}\"\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:02d} | \"\n",
    "            f\"train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n",
    "            f\"val_acc={val_metrics['acc']:.4f} | val_macro_f1={val_metrics['macro_f1']:.4f} | val_auc={auc_str} | \"\n",
    "            f\"best_val_loss={early.best_score:.4f} | patience={early.counter}/{early.patience}\"\n",
    "        )\n",
    "\n",
    "        if early.early_stop:\n",
    "            print(\"[Early Stop] Training stopped.\")\n",
    "            break\n",
    "\n",
    "    # load best\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
    "    print(f\"[DONE] Best model saved: {BEST_MODEL_PATH}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_mil(\n",
    "    slide_split_df=slide_split,\n",
    "    top_k=10,          \n",
    "    max_patches=300,   \n",
    "    sample_mode=\"random\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bonryu]",
   "language": "python",
   "name": "conda-env-bonryu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
