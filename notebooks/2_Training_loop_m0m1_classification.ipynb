{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb6300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "import json\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78ec9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "LABEL_CSV = Path(\"/home/khdp-user/workspace/dataset/CSV/m0m1_label.csv\")\n",
    "PATCH_ROOT = Path(\"/home/khdp-user/workspace/dataset/Glom_M0M1\")\n",
    "PATCH_SIZE = 512\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "OUT_DIR = Path(\"/home/khdp-user/workspace/m0m1_run_cls\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "CSV_PATH = os.path.join(OUT_DIR, \"dataset.csv\")\n",
    "BEST_MODEL_PATH = OUT_DIR / \"best_model.pt\"\n",
    "SPLIT_CSV_PATH  = OUT_DIR / \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cee247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index] scanning patches...\n",
      "Total patches indexed: 1190\n"
     ]
    }
   ],
   "source": [
    "def build_patch_index(root: Path, exts=(\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\")):\n",
    "    idx = {}\n",
    "    for ext in exts:\n",
    "        for p in root.rglob(f\"*{ext}\"):\n",
    "            idx[p.name] = p\n",
    "    return idx\n",
    "\n",
    "print(\"[Index] scanning patches...\")\n",
    "patch_index = build_patch_index(PATCH_ROOT)\n",
    "print(\"Total patches indexed:\", len(patch_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c72fb8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (1190, 3) missing: 0\n",
      "y\n",
      "0    661\n",
      "1    529\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv(LABEL_CSV)\n",
    "\n",
    "rows = []\n",
    "missing = 0\n",
    "for _, r in label_df.iterrows():\n",
    "    name = r[\"patch_name\"]\n",
    "    p = patch_index.get(name)\n",
    "    if p is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "\n",
    "    y = 1 if r[\"target\"].lower() == \"m1\" else 0\n",
    "    rows.append({\n",
    "        \"name\": name,\n",
    "        \"path\": str(p),\n",
    "        \"y\": y\n",
    "    })\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"df shape:\", df.shape, \"missing:\", missing)\n",
    "print(df[\"y\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e69b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch-level distribution\n",
      "y        0    1\n",
      "split          \n",
      "test    98   51\n",
      "train  465  413\n",
      "val     98   65\n",
      "\n",
      "Slide-level distribution (#slides)\n",
      "split\n",
      "train    81\n",
      "test     12\n",
      "val       9\n",
      "Name: count, dtype: int64\n",
      "[OK] CSV saved: /home/khdp-user/workspace/m0m1_run_cls/dataset.csv  (patches=1190)\n"
     ]
    }
   ],
   "source": [
    "def get_slide_id_from_patch_name(patch_name: str):\n",
    "    return patch_name.split(\"_PAS\")[0]\n",
    "\n",
    "def stratified_split_slide(\n",
    "    slide_df,\n",
    "    y_col=\"slide_y\",\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    seed=42,\n",
    "):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    slide_split = {}\n",
    "\n",
    "    for cls, sub in slide_df.groupby(y_col):\n",
    "        slide_ids = sub[\"slide_id\"].values\n",
    "        rng.shuffle(slide_ids)\n",
    "\n",
    "        n = len(slide_ids)\n",
    "        n_tr = int(n * train_ratio)\n",
    "        n_va = int(n * val_ratio)\n",
    "\n",
    "        for sid in slide_ids[:n_tr]:\n",
    "            slide_split[sid] = \"train\"\n",
    "        for sid in slide_ids[n_tr:n_tr+n_va]:\n",
    "            slide_split[sid] = \"val\"\n",
    "        for sid in slide_ids[n_tr+n_va:]:\n",
    "            slide_split[sid] = \"test\"\n",
    "\n",
    "    return slide_split\n",
    "\n",
    "\n",
    "df[\"slide_id\"] = df[\"name\"].apply(get_slide_id_from_patch_name)\n",
    "\n",
    "slide_df = (\n",
    "    df.groupby(\"slide_id\")[\"y\"]\n",
    "      .max()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"y\": \"slide_y\"})\n",
    ")\n",
    "\n",
    "slide_split = stratified_split_slide(slide_df)\n",
    "\n",
    "df[\"split\"] = df[\"slide_id\"].map(slide_split)\n",
    "assert df[\"split\"].isna().sum() == 0\n",
    "\n",
    "print(\"Patch-level distribution\")\n",
    "print(pd.crosstab(df[\"split\"], df[\"y\"]))\n",
    "\n",
    "slide_view = (\n",
    "    df[[\"slide_id\", \"split\"]]\n",
    "    .drop_duplicates(\"slide_id\")\n",
    ")\n",
    "print(\"\\nSlide-level distribution (#slides)\")\n",
    "print(slide_view[\"split\"].value_counts())\n",
    "\n",
    "slide_view = slide_df.merge(\n",
    "    df[[\"slide_id\", \"split\"]].drop_duplicates(\"slide_id\"),\n",
    "    on=\"slide_id\"\n",
    ")\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f\"[OK] CSV saved: {CSV_PATH}  (patches={len(df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9456148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchClsDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row[\"path\"])\n",
    "        if img is None:\n",
    "            raise RuntimeError(row[\"path\"])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "\n",
    "        y = torch.tensor(row[\"y\"]).long()\n",
    "        return img, y\n",
    "    \n",
    "def get_transforms():\n",
    "    train_tf = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Resize(PATCH_SIZE, PATCH_SIZE),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    val_tf = A.Compose([\n",
    "        A.Resize(PATCH_SIZE, PATCH_SIZE),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    return train_tf, val_tf\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0, mode=\"min\"):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def step(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return True\n",
    "\n",
    "        improved = (\n",
    "            score < self.best_score - self.min_delta\n",
    "            if self.mode == \"min\"\n",
    "            else score > self.best_score + self.min_delta\n",
    "        )\n",
    "\n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            return True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            return False\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = timm.create_model(\n",
    "        \"resnet50\",\n",
    "        pretrained=True,\n",
    "        num_classes=2 \n",
    "    )\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    n = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "\n",
    "    val_loss = total_loss / max(n, 1)\n",
    "    val_acc  = correct / max(n, 1)\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def train(df):\n",
    "    train_tf, val_tf = get_transforms()\n",
    "\n",
    "    df_tr = df[df.split == \"train\"]\n",
    "    df_va = df[df.split == \"val\"]\n",
    "\n",
    "    dl_tr = DataLoader(\n",
    "        PatchClsDataset(df_tr, train_tf),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    dl_va = DataLoader(\n",
    "        PatchClsDataset(df_va, val_tf),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    early_stopper = EarlyStopping(\n",
    "        patience=5,\n",
    "        min_delta=1e-4,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # ==================\n",
    "        # Train\n",
    "        # ==================\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        pbar = tqdm(dl_tr, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for x, y in pbar:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            pbar.set_postfix(train_loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        train_loss = float(np.mean(train_losses))\n",
    "\n",
    "        # ==================\n",
    "        # Validation\n",
    "        # ==================\n",
    "        val_loss, val_acc = validate(model, dl_va, criterion)\n",
    "\n",
    "        # ==================\n",
    "        # Early Stopping\n",
    "        # ==================\n",
    "        is_best = early_stopper.step(val_loss)\n",
    "        if is_best:\n",
    "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "\n",
    "        # ==================\n",
    "        # Logging\n",
    "        # ==================\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "            f\"train_loss={train_loss:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f} | \"\n",
    "            f\"val_acc={val_acc:.4f} | \"\n",
    "            f\"best_val_loss={early_stopper.best_score:.4f} | \"\n",
    "            f\"patience={early_stopper.counter}/{early_stopper.patience}\"\n",
    "        )\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"[Early Stop] Training stopped.\")\n",
    "            break\n",
    "\n",
    "    print(f\"[DONE] Best model saved to {BEST_MODEL_PATH}\")\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749cf519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 14/14 [00:17<00:00,  1.26s/it, train_loss=0.6778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | train_loss=0.6869 | val_loss=0.6752 | val_acc=0.6319 | best_val_loss=0.6752 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 14/14 [00:12<00:00,  1.12it/s, train_loss=0.6861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | train_loss=0.6754 | val_loss=0.6552 | val_acc=0.7117 | best_val_loss=0.6552 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, train_loss=0.6820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | train_loss=0.6623 | val_loss=0.6258 | val_acc=0.7669 | best_val_loss=0.6258 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, train_loss=0.6203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | train_loss=0.6449 | val_loss=0.5998 | val_acc=0.7546 | best_val_loss=0.5998 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, train_loss=0.6429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | train_loss=0.6289 | val_loss=0.5780 | val_acc=0.7546 | best_val_loss=0.5780 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, train_loss=0.5897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | train_loss=0.6104 | val_loss=0.5504 | val_acc=0.7546 | best_val_loss=0.5504 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, train_loss=0.5635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | train_loss=0.5925 | val_loss=0.5460 | val_acc=0.7607 | best_val_loss=0.5460 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, train_loss=0.5705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | train_loss=0.5685 | val_loss=0.5394 | val_acc=0.7546 | best_val_loss=0.5394 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, train_loss=0.6061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | train_loss=0.5486 | val_loss=0.5320 | val_acc=0.7485 | best_val_loss=0.5320 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, train_loss=0.5460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | train_loss=0.5179 | val_loss=0.5058 | val_acc=0.7423 | best_val_loss=0.5058 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, train_loss=0.5245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | train_loss=0.4859 | val_loss=0.5132 | val_acc=0.7546 | best_val_loss=0.5058 | patience=1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, train_loss=0.4353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | train_loss=0.4422 | val_loss=0.4752 | val_acc=0.7853 | best_val_loss=0.4752 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, train_loss=0.4964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | train_loss=0.4034 | val_loss=0.4846 | val_acc=0.7791 | best_val_loss=0.4752 | patience=1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, train_loss=0.2954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | train_loss=0.3624 | val_loss=0.4606 | val_acc=0.7607 | best_val_loss=0.4606 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, train_loss=0.3350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | train_loss=0.3210 | val_loss=0.5048 | val_acc=0.7669 | best_val_loss=0.4606 | patience=1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, train_loss=0.3751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | train_loss=0.2782 | val_loss=0.4559 | val_acc=0.8037 | best_val_loss=0.4559 | patience=0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, train_loss=0.1873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | train_loss=0.2269 | val_loss=0.4972 | val_acc=0.7607 | best_val_loss=0.4559 | patience=1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, train_loss=0.2058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | train_loss=0.1843 | val_loss=0.5871 | val_acc=0.7546 | best_val_loss=0.4559 | patience=2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, train_loss=0.1711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | train_loss=0.1703 | val_loss=0.4917 | val_acc=0.7975 | best_val_loss=0.4559 | patience=3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 14/14 [00:09<00:00,  1.54it/s, train_loss=0.1680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | train_loss=0.1559 | val_loss=0.5876 | val_acc=0.7669 | best_val_loss=0.4559 | patience=4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, train_loss=0.1626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | train_loss=0.1443 | val_loss=0.6707 | val_acc=0.7362 | best_val_loss=0.4559 | patience=5/5\n",
      "[Early Stop] Training stopped.\n",
      "[DONE] Best model saved to /home/khdp-user/workspace/m0m1_run_cls/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "model = train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6df760f-e1ab-4e00-b2ae-d0736c251488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Training environment saved: /home/khdp-user/workspace/m0m1_run_cls/training_env.json\n"
     ]
    }
   ],
   "source": [
    "def save_training_env(out_dir):\n",
    "    env = {\n",
    "        \"TASK_TYPE\": 'classification',\n",
    "        \"PATCH_SIZE\": PATCH_SIZE,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"EPOCHS\": EPOCHS,\n",
    "        \"LR\": LR,\n",
    "        \"TEST_RATIO\": 0.1,\n",
    "        \"VAL_RATIO\": 0.1,\n",
    "        \"target_mag\": 10.0,\n",
    "        \"DEVICE\": DEVICE,\n",
    "        \"cuda_available\": torch.cuda.is_available(),\n",
    "        \"torch_version\": torch.__version__,\n",
    "        \"python_version\": platform.python_version(),\n",
    "    }\n",
    "\n",
    "    save_path = os.path.join(out_dir, \"training_env.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(env, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Training environment saved: {save_path}\")\n",
    "save_training_env(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f4259-1eb5-44f7-a54f-34d92df7a80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
