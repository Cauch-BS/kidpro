{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH    = \"/home/khdp-user/workspace/dataset/Models/Infla_run_seg/dataset.csv\"\n",
    "WEIGHT_PATH = \"/home/khdp-user/workspace/dataset/Models/Infla_run_seg/best_model.pt\"\n",
    "SVS_DIR     = Path(\"/home/khdp-user/workspace/dataset/Slide\")\n",
    "\n",
    "LAYER_IDS   = [1]          # binary: len==1, multiclass: 여러 개\n",
    "TASK_TYPE   = \"binary\"     # \"binary\" | \"multiclass\" \n",
    "PATCH_SIZE  = 512\n",
    "TARGET_MAG  = 10.0\n",
    "THRESH      = 0.5          # binary only\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Utils\n",
    "# ============================================================\n",
    "def parse_xy_from_name(patch_name: str):\n",
    "    # ..._X0Y0_034816_010240.png\n",
    "    stem = Path(patch_name).stem\n",
    "    parts = stem.split(\"_\")\n",
    "    x0 = int(parts[-2])\n",
    "    y0 = int(parts[-1])\n",
    "    return x0, y0\n",
    "\n",
    "\n",
    "def dice_iou(pred01: np.ndarray, gt01: np.ndarray, eps=1e-6):\n",
    "    pred01 = pred01.astype(bool)\n",
    "    gt01   = gt01.astype(bool)\n",
    "\n",
    "    inter = np.logical_and(pred01, gt01).sum()\n",
    "    union = np.logical_or(pred01, gt01).sum()\n",
    "\n",
    "    dice = (2 * inter + eps) / (pred01.sum() + gt01.sum() + eps)\n",
    "    iou  = (inter + eps) / (union + eps)\n",
    "    return float(dice), float(iou)\n",
    "\n",
    "\n",
    "def safe_img_path(row):\n",
    "    \"\"\"CSV의 path가 파일일 수도, 디렉토리일 수도 있는 케이스 처리.\"\"\"\n",
    "    p = Path(row[\"path\"])\n",
    "    if p.is_file():\n",
    "        return p\n",
    "    return p / row[\"name\"]\n",
    "\n",
    "\n",
    "def get_slide_id_from_name(patch_name: str):\n",
    "    # \"SLIDEID_PAS_...\" -> \"SLIDEID\"\n",
    "    return patch_name.split(\"_PAS\")[0]\n",
    "\n",
    "\n",
    "def infer_task_type(task_type: str, layer_ids):\n",
    "    if task_type in (\"binary\", \"multiclass\"):\n",
    "        return task_type\n",
    "    # auto\n",
    "    return \"binary\" if len(layer_ids) == 1 else \"multiclass\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Transform (MUST match training/val)\n",
    "# ============================================================\n",
    "def get_infer_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(PATCH_SIZE, PATCH_SIZE),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Model\n",
    "# ============================================================\n",
    "def build_model(layer_ids, task_type: str):\n",
    "    task_type = infer_task_type(task_type, layer_ids)\n",
    "    is_binary = (task_type == \"binary\")\n",
    "\n",
    "    if is_binary:\n",
    "        classes = 1\n",
    "    else:\n",
    "        # background + len(layer_ids)\n",
    "        classes = 1 + len(layer_ids)\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None,   # weight는 state_dict로 로드됨\n",
    "        in_channels=3,\n",
    "        classes=classes,\n",
    "        activation=None,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(WEIGHT_PATH, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model, is_binary, task_type\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Patch-level eval\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def eval_patch_level(model, task_type: str, df_test: pd.DataFrame):\n",
    "    tf = get_infer_transform()\n",
    "    rows = []\n",
    "\n",
    "    is_binary = (task_type == \"binary\")\n",
    "\n",
    "    for _, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Patch-level eval\"):\n",
    "        img_path   = safe_img_path(row)\n",
    "        patch_name = row[\"name\"]\n",
    "        slide_id   = get_slide_id_from_name(patch_name)\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        out = tf(image=img, mask=np.zeros(img.shape[:2], np.uint8))\n",
    "        x = out[\"image\"].unsqueeze(0).to(DEVICE)  # (1,3,H,W)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        slide_root = img_path.parents[1]         # .../SLIDE_ID_PAS\n",
    "        mask_root  = slide_root / \"masks\"\n",
    "\n",
    "        if is_binary:\n",
    "            gt_path = mask_root / f\"layer{LAYER_IDS[0]}\" / patch_name\n",
    "            gt = (cv2.imread(str(gt_path), 0) > 127) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), bool)\n",
    "\n",
    "            prob = torch.sigmoid(logits)[0, 0].cpu().numpy()\n",
    "            pred = (prob > THRESH)\n",
    "\n",
    "            d, i = dice_iou(pred, gt)\n",
    "            rows.append({\"slide_id\": slide_id, \"layer\": LAYER_IDS[0], \"dice\": d, \"iou\": i})\n",
    "\n",
    "        else:\n",
    "            # multiclass: logits (1,C,H,W) -> argmax (H,W), class 0..K\n",
    "            probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "            pred_cls = np.argmax(probs, axis=0)\n",
    "\n",
    "            for k, lid in enumerate(LAYER_IDS, start=1):\n",
    "                gt_path = mask_root / f\"layer{lid}\" / patch_name\n",
    "                gt = (cv2.imread(str(gt_path), 0) > 127) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), bool)\n",
    "\n",
    "                pred = (pred_cls == k)\n",
    "                d, i = dice_iou(pred, gt)\n",
    "                rows.append({\"slide_id\": slide_id, \"layer\": lid, \"dice\": d, \"iou\": i})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Slide-level stitching eval (TARGET_MAG canvas)\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def eval_slide_level_stitching(model, task_type: str, df_slide: pd.DataFrame):\n",
    "    tf = get_infer_transform()\n",
    "    is_binary = (task_type == \"binary\")\n",
    "\n",
    "    any_name = df_slide.iloc[0][\"name\"]\n",
    "    slide_id = get_slide_id_from_name(any_name)\n",
    "    svs_path = SVS_DIR / f\"{slide_id}_PAS.svs\"\n",
    "    if not svs_path.exists():\n",
    "        return None\n",
    "\n",
    "    slide = openslide.OpenSlide(str(svs_path))\n",
    "\n",
    "    # base mag from Aperio property (fallback 40)\n",
    "    BASE_MAG = float(slide.properties.get(\"aperio.AppMag\", 40.0))\n",
    "    down = BASE_MAG / float(TARGET_MAG)\n",
    "\n",
    "    W0, H0 = slide.level_dimensions[0]\n",
    "    Wt, Ht = int(W0 / down), int(H0 / down)\n",
    "\n",
    "    # patch downscale to target mag canvas\n",
    "    scale = 1.0 / down\n",
    "    tw = max(1, int(PATCH_SIZE * scale))\n",
    "    th = max(1, int(PATCH_SIZE * scale))\n",
    "\n",
    "    if is_binary:\n",
    "        pred_canvas = np.zeros((Ht, Wt), np.uint8)\n",
    "        gt_canvas   = np.zeros((Ht, Wt), np.uint8)\n",
    "    else:\n",
    "        pred_canvas = {lid: np.zeros((Ht, Wt), np.uint8) for lid in LAYER_IDS}\n",
    "        gt_canvas   = {lid: np.zeros((Ht, Wt), np.uint8) for lid in LAYER_IDS}\n",
    "\n",
    "    for _, row in df_slide.iterrows():\n",
    "        img_path   = safe_img_path(row)\n",
    "        patch_name = row[\"name\"]\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        out = tf(image=img, mask=np.zeros(img.shape[:2], np.uint8))\n",
    "        x = out[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        x0, y0 = parse_xy_from_name(patch_name)\n",
    "        xt, yt = int(x0 / down), int(y0 / down)\n",
    "\n",
    "        slide_root = img_path.parents[1]\n",
    "        mask_root  = slide_root / \"masks\"\n",
    "\n",
    "        if is_binary:\n",
    "            prob = torch.sigmoid(logits)[0, 0].cpu().numpy()\n",
    "            pred_patch = (prob > THRESH).astype(np.uint8)\n",
    "\n",
    "            gt_path = mask_root / f\"layer{LAYER_IDS[0]}\" / patch_name\n",
    "            gt_patch = (cv2.imread(str(gt_path), 0) > 127).astype(np.uint8) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), np.uint8)\n",
    "\n",
    "            pred_small = cv2.resize(pred_patch, (tw, th), interpolation=cv2.INTER_NEAREST)\n",
    "            gt_small   = cv2.resize(gt_patch,   (tw, th), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            if yt + th > Ht or xt + tw > Wt:\n",
    "                continue\n",
    "\n",
    "            pred_canvas[yt:yt+th, xt:xt+tw] = np.maximum(pred_canvas[yt:yt+th, xt:xt+tw], pred_small)\n",
    "            gt_canvas[yt:yt+th, xt:xt+tw]   = np.maximum(gt_canvas[yt:yt+th, xt:xt+tw],   gt_small)\n",
    "\n",
    "        else:\n",
    "            probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "            pred_cls = np.argmax(probs, axis=0).astype(np.uint8)  # 0..K\n",
    "\n",
    "            if yt + th > Ht or xt + tw > Wt:\n",
    "                continue\n",
    "\n",
    "            for k, lid in enumerate(LAYER_IDS, start=1):\n",
    "                pred_patch = (pred_cls == k).astype(np.uint8)\n",
    "\n",
    "                gt_path = mask_root / f\"layer{lid}\" / patch_name\n",
    "                gt_patch = (cv2.imread(str(gt_path), 0) > 127).astype(np.uint8) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), np.uint8)\n",
    "\n",
    "                pred_small = cv2.resize(pred_patch, (tw, th), interpolation=cv2.INTER_NEAREST)\n",
    "                gt_small   = cv2.resize(gt_patch,   (tw, th), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                pred_canvas[lid][yt:yt+th, xt:xt+tw] = np.maximum(pred_canvas[lid][yt:yt+th, xt:xt+tw], pred_small)\n",
    "                gt_canvas[lid][yt:yt+th, xt:xt+tw]   = np.maximum(gt_canvas[lid][yt:yt+th, xt:xt+tw],   gt_small)\n",
    "\n",
    "    slide.close()\n",
    "\n",
    "    if is_binary:\n",
    "        d, i = dice_iou(pred_canvas, gt_canvas)\n",
    "        return {\"slide_id\": slide_id, \"layer\": LAYER_IDS[0], \"dice\": d, \"iou\": i}\n",
    "    else:\n",
    "        out_rows = []\n",
    "        for lid in LAYER_IDS:\n",
    "            d, i = dice_iou(pred_canvas[lid], gt_canvas[lid])\n",
    "            out_rows.append({\"slide_id\": slide_id, \"layer\": lid, \"dice\": d, \"iou\": i})\n",
    "        return out_rows\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main (mode 선택 실행)\n",
    "# ============================================================\n",
    "def run(mode: str):\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df_test = df[df[\"split\"].astype(str).str.lower() == \"test\"].reset_index(drop=True)\n",
    "    if len(df_test) == 0:\n",
    "        raise RuntimeError(\"No test rows found in CSV (split == test).\")\n",
    "\n",
    "    model, is_binary, task_type = build_model(LAYER_IDS, TASK_TYPE)\n",
    "\n",
    "    print(f\"[INFO] TASK: {task_type} | LAYER_IDS={LAYER_IDS} | THRESH={THRESH if task_type=='binary' else 'N/A'}\")\n",
    "    print(f\"[INFO] DEVICE: {DEVICE} | #test patches: {len(df_test)}\")\n",
    "\n",
    "    if mode in (\"patch\", \"both\"):\n",
    "        patch_df = eval_patch_level(model, task_type, df_test)\n",
    "\n",
    "        print(\"\\n[PATCH-LEVEL MEAN]\")\n",
    "        if not patch_df.empty:\n",
    "            print(patch_df.groupby(\"layer\")[[\"dice\", \"iou\"]].mean())\n",
    "        else:\n",
    "            print(\"No patch metrics computed (check paths).\")\n",
    "\n",
    "    if mode in (\"slide\", \"both\"):\n",
    "        slide_rows = []\n",
    "        group_key = df_test[\"name\"].astype(str).apply(get_slide_id_from_name)\n",
    "\n",
    "        for slide_id, df_slide in tqdm(df_test.groupby(group_key), desc=\"Slide stitching\"):\n",
    "            res = eval_slide_level_stitching(model, task_type, df_slide)\n",
    "            if res is None:\n",
    "                continue\n",
    "            if task_type == \"binary\":\n",
    "                slide_rows.append(res)\n",
    "            else:\n",
    "                slide_rows.extend(res)\n",
    "\n",
    "        slide_df = pd.DataFrame(slide_rows)\n",
    "\n",
    "        print(\"\\n[SLIDE-LEVEL (STITCHING) MEAN]\")\n",
    "        if not slide_df.empty:\n",
    "            print(slide_df.groupby(\"layer\")[[\"dice\", \"iou\"]].mean())\n",
    "            if task_type != \"binary\":\n",
    "                macro = slide_df.groupby(\"slide_id\")[[\"dice\", \"iou\"]].mean().mean()\n",
    "                print(\"\\n[SLIDE-LEVEL MACRO (mean over layers, then over slides)]\")\n",
    "                print(macro)\n",
    "        else:\n",
    "            print(\"No slide metrics computed (check SVS paths / naming).\")\n",
    "\n",
    "    print(\"\\n[OK] Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(mode=\"both\") # patch, slide, both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
