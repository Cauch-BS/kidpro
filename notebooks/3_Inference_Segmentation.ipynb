{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH   = \"/home/khdp-user/workspace/IFTA_run_seg/dataset.csv\"     \n",
    "WEIGHT_PATH = \"/home/khdp-user/workspace/IFTA_run_seg/best_model.pt\"\n",
    "SVS_DIR = Path(\"/home/khdp-user/workspace/dataset/Slide\")\n",
    "LAYER_IDS = [1,2,3]                  # binary 기준\n",
    "TASK_TYPE = \"multiclass\" \n",
    "PATCH_SIZE = 256\n",
    "TARGET_MAG = 10.0\n",
    "BATCH_SIZE = 1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "THRESH = 0.5\n",
    "AGG = \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Utils\n",
    "# -------------------------\n",
    "def parse_xy_from_name(patch_name: str):\n",
    "    # ..._X0Y0_034816_010240.png\n",
    "    stem = Path(patch_name).stem\n",
    "    parts = stem.split(\"_\")\n",
    "    x0 = int(parts[-2])\n",
    "    y0 = int(parts[-1])\n",
    "    return x0, y0\n",
    "\n",
    "\n",
    "def dice_iou(pred01: np.ndarray, gt01: np.ndarray, eps=1e-6):\n",
    "    pred01 = pred01.astype(bool)\n",
    "    gt01   = gt01.astype(bool)\n",
    "\n",
    "    inter = np.logical_and(pred01, gt01).sum()\n",
    "    union = np.logical_or(pred01, gt01).sum()\n",
    "\n",
    "    dice = (2 * inter + eps) / (pred01.sum() + gt01.sum() + eps)\n",
    "    iou  = (inter + eps) / (union + eps)\n",
    "    return float(dice), float(iou)\n",
    "\n",
    "\n",
    "def safe_img_path(row):\n",
    "    \"\"\"CSV의 path가 디렉토리일 수도, 파일일 수도 있는 케이스 둘 다 처리.\"\"\"\n",
    "    p = Path(row[\"path\"])\n",
    "    if p.is_file():\n",
    "        return p\n",
    "    return p / row[\"name\"]\n",
    "\n",
    "\n",
    "def get_slide_id_from_name(patch_name: str):\n",
    "    # 11_01_0144_PAS_... -> 11_01_0144\n",
    "    return patch_name.split(\"_PAS\")[0]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Model\n",
    "# -------------------------\n",
    "def build_model(layer_ids):\n",
    "    is_binary = (len(layer_ids) == 1)\n",
    "\n",
    "    if is_binary:\n",
    "        classes = 1\n",
    "    else:\n",
    "        # background + len(layer_ids)\n",
    "        classes = 1 + len(layer_ids)\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None,   # 테스트 시엔 None (학습 때 imagenet 써도 weight는 로드됨)\n",
    "        in_channels=3,\n",
    "        classes=classes,\n",
    "        activation=None,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(WEIGHT_PATH, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model, is_binary\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Patch-level eval (optional)\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def eval_patch_level(model, is_binary, df_test):\n",
    "    rows = []\n",
    "\n",
    "    for _, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Patch-level eval\"):\n",
    "        img_path = safe_img_path(row)\n",
    "        patch_name = row[\"name\"]\n",
    "        slide_id = get_slide_id_from_name(patch_name)\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        x = torch.from_numpy(img).permute(2,0,1).float().unsqueeze(0) / 255.\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        # GT 로드 (각 layer별 mask png 존재한다고 가정)\n",
    "        slide_root = img_path.parents[1]  # .../SLIDE_ID_PAS\n",
    "        mask_root = slide_root / \"masks\"\n",
    "\n",
    "        if is_binary:\n",
    "            gt_path = mask_root / f\"layer{LAYER_IDS[0]}\" / patch_name\n",
    "            gt = (cv2.imread(str(gt_path), 0) > 127) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), bool)\n",
    "\n",
    "            prob = torch.sigmoid(logits)[0,0].cpu().numpy()\n",
    "            pred = prob > THRESH\n",
    "\n",
    "            d, i = dice_iou(pred, gt)\n",
    "            rows.append({\"slide_id\": slide_id, \"layer\": LAYER_IDS[0], \"dice\": d, \"iou\": i})\n",
    "        else:\n",
    "            gt_stack = []\n",
    "            for lid in LAYER_IDS:\n",
    "                gp = mask_root / f\"layer{lid}\" / patch_name\n",
    "                g = (cv2.imread(str(gp), 0) > 127) if gp.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), bool)\n",
    "                gt_stack.append(g)\n",
    "\n",
    "            pred_cls = torch.argmax(torch.softmax(logits, dim=1), dim=1)[0].cpu().numpy()  # 0..K\n",
    "            # layer index: 1..K corresponds to LAYER_IDS order\n",
    "            for k, lid in enumerate(LAYER_IDS, start=1):\n",
    "                pred = (pred_cls == k)\n",
    "                gt   = gt_stack[k-1]\n",
    "                d, i = dice_iou(pred, gt)\n",
    "                rows.append({\"slide_id\": slide_id, \"layer\": lid, \"dice\": d, \"iou\": i})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Slide-level stitching eval (true WSI-level at TARGET_MAG)\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def eval_slide_level_stitching(model, is_binary, df_slide):\n",
    "    # slide open\n",
    "    any_name = df_slide.iloc[0][\"name\"]\n",
    "    slide_id = get_slide_id_from_name(any_name)\n",
    "    svs_path = SVS_DIR / f\"{slide_id}_PAS.svs\"\n",
    "    if not svs_path.exists():\n",
    "        return None\n",
    "\n",
    "    slide = openslide.OpenSlide(str(svs_path))\n",
    "\n",
    "    BASE_MAG = float(slide.properties.get(\"aperio.AppMag\", 40.0))\n",
    "    down = BASE_MAG / float(TARGET_MAG)\n",
    "\n",
    "    W0, H0 = slide.level_dimensions[0]\n",
    "    Wt, Ht = int(W0 / down), int(H0 / down)\n",
    "\n",
    "    if is_binary:\n",
    "        pred_canvas = np.zeros((Ht, Wt), np.uint8)\n",
    "        gt_canvas   = np.zeros((Ht, Wt), np.uint8)\n",
    "    else:\n",
    "        # per-layer canvas\n",
    "        pred_canvas = {lid: np.zeros((Ht, Wt), np.uint8) for lid in LAYER_IDS}\n",
    "        gt_canvas   = {lid: np.zeros((Ht, Wt), np.uint8) for lid in LAYER_IDS}\n",
    "\n",
    "    # stitch\n",
    "    for _, row in df_slide.iterrows():\n",
    "        img_path = safe_img_path(row)\n",
    "        patch_name = row[\"name\"]\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        x = torch.from_numpy(img).permute(2,0,1).float().unsqueeze(0) / 255.\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        x0, y0 = parse_xy_from_name(patch_name)\n",
    "        xt, yt = int(x0 / down), int(y0 / down)\n",
    "\n",
    "        # GT root\n",
    "        slide_root = img_path.parents[1]\n",
    "        mask_root = slide_root / \"masks\"\n",
    "\n",
    "        if is_binary:\n",
    "            prob = torch.sigmoid(logits)[0,0].cpu().numpy()\n",
    "            pred_patch = (prob > THRESH).astype(np.uint8)\n",
    "\n",
    "            gt_path = mask_root / f\"layer{LAYER_IDS[0]}\" / patch_name\n",
    "            gt_patch = (cv2.imread(str(gt_path), 0) > 127).astype(np.uint8) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), np.uint8)\n",
    "\n",
    "            h, w = pred_patch.shape\n",
    "            if yt+h > Ht or xt+w > Wt:\n",
    "                continue\n",
    "\n",
    "            pred_canvas[yt:yt+h, xt:xt+w] = np.maximum(pred_canvas[yt:yt+h, xt:xt+w], pred_patch)\n",
    "            gt_canvas[yt:yt+h, xt:xt+w]   = np.maximum(gt_canvas[yt:yt+h, xt:xt+w], gt_patch)\n",
    "        else:\n",
    "            probs = torch.softmax(logits, dim=1)[0].cpu().numpy()  # (1+K,H,W)\n",
    "            pred_cls = np.argmax(probs, axis=0).astype(np.uint8)   # 0..K\n",
    "\n",
    "            h, w = pred_cls.shape\n",
    "            if yt+h > Ht or xt+w > Wt:\n",
    "                continue\n",
    "\n",
    "            for k, lid in enumerate(LAYER_IDS, start=1):\n",
    "                pred_patch = (pred_cls == k).astype(np.uint8)\n",
    "\n",
    "                gt_path = mask_root / f\"layer{lid}\" / patch_name\n",
    "                gt_patch = (cv2.imread(str(gt_path), 0) > 127).astype(np.uint8) if gt_path.exists() else np.zeros((PATCH_SIZE, PATCH_SIZE), np.uint8)\n",
    "\n",
    "                pred_canvas[lid][yt:yt+h, xt:xt+w] = np.maximum(pred_canvas[lid][yt:yt+h, xt:xt+w], pred_patch)\n",
    "                gt_canvas[lid][yt:yt+h, xt:xt+w]   = np.maximum(gt_canvas[lid][yt:yt+h, xt:xt+w], gt_patch)\n",
    "\n",
    "    # compute metrics\n",
    "    if is_binary:\n",
    "        d, i = dice_iou(pred_canvas, gt_canvas)\n",
    "        slide.close()\n",
    "        return {\n",
    "            \"slide_id\": slide_id,\n",
    "            \"layer\": LAYER_IDS[0],\n",
    "            \"dice\": d,\n",
    "            \"iou\": i,\n",
    "        }\n",
    "    else:\n",
    "        out = []\n",
    "        for lid in LAYER_IDS:\n",
    "            d, i = dice_iou(pred_canvas[lid], gt_canvas[lid])\n",
    "            out.append({\"slide_id\": slide_id, \"layer\": lid, \"dice\": d, \"iou\": i})\n",
    "        slide.close()\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df_test = df[df[\"split\"].astype(str).str.lower() == \"test\"].reset_index(drop=True)\n",
    "    if len(df_test) == 0:\n",
    "        raise RuntimeError(\"No test rows found in CSV (split == test).\")\n",
    "    model, is_binary = build_model(LAYER_IDS)\n",
    "    print(f\"[INFO] TASK: {'binary(sigmoid)' if is_binary else 'multiclass(softmax)'} | LAYER_IDS={LAYER_IDS}\")\n",
    "    print(f\"[INFO] DEVICE: {DEVICE} | #test patches: {len(df_test)}\")\n",
    "    patch_df = eval_patch_level(model, is_binary, df_test)\n",
    "#     patch_df.to_csv(\"test_patch_metrics.csv\", index=False)\n",
    "    print(\"\\n[PATCH-LEVEL MEAN]\")\n",
    "    if not patch_df.empty:\n",
    "        print(patch_df.groupby(\"layer\")[[\"dice\",\"iou\"]].mean())\n",
    "    else:\n",
    "        print(\"No patch metrics computed (check paths).\")\n",
    "    slide_rows = []\n",
    "    group_key = df_test[\"name\"].astype(str).apply(get_slide_id_from_name)\n",
    "    for slide_id, df_slide in tqdm(df_test.groupby(group_key), desc=\"Slide stitching\"):\n",
    "        res = eval_slide_level_stitching(model, is_binary, df_slide)\n",
    "        if res is None:\n",
    "            continue\n",
    "        if is_binary:\n",
    "            slide_rows.append(res)\n",
    "        else:\n",
    "            slide_rows.extend(res)\n",
    "\n",
    "    slide_df = pd.DataFrame(slide_rows)\n",
    "#     slide_df.to_csv(\"test_slide_stitching_metrics.csv\", index=False)\n",
    "\n",
    "    print(\"\\n[SLIDE-LEVEL (STITCHING) MEAN]\")\n",
    "    if not slide_df.empty:\n",
    "        print(slide_df.groupby(\"layer\")[[\"dice\",\"iou\"]].mean())\n",
    "        # multiclass면 macro 평균도 출력\n",
    "        if not is_binary:\n",
    "            macro = slide_df.groupby(\"slide_id\")[[\"dice\",\"iou\"]].mean().mean()\n",
    "            print(\"\\n[SLIDE-LEVEL MACRO (mean over layers, then over slides)]\")\n",
    "            print(macro)\n",
    "    else:\n",
    "        print(\"No slide metrics computed (check SVS paths / naming).\")\n",
    "\n",
    "    print(\"\\n[OK] Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
